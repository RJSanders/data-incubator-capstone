{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Project\n",
    "\n",
    "The goal of this project is to create quantitative profiles of online communities using voting data from Reddit.\n",
    "\n",
    "## The Data Set\n",
    "\n",
    "The current data set is a collection of [44 million public Reddit votes](https://www.kaggle.com/josephleake/huge-collection-of-reddit-votes/) collected by Joseph Leake. Each vote includes the subreddit, the time at which the vote was cast, the username of the voter, and whether the vote was positive or negative.\n",
    "\n",
    "The data includes a separate file listing the topics on which the voting occurred.\n",
    "\n",
    "## Questions of Interest\n",
    "\n",
    "- How positive or negative is the voting trend within a community? How much controversy (measured as an upvote/downvote ratio close to 1) is there?\n",
    "- Among users, are upvotes/downvote patterns consistent across different subreddits?\n",
    "- How likely are users within a community to vote according to the consensus?\n",
    "- Which subreddits are more or less popular relative to the voters of a particular subreddit?\n",
    "\n",
    "## Initial Analysis\n",
    "\n",
    "By tabulating the total number of votes and submissions by subreddit, we can obtain the following:\n",
    "\n",
    "![Bar Graph](https://rjsanders.github.io/saucer/bar_graph.png)\n",
    "\n",
    "From this graph, we can see that the top five subreddits by votes are r/funny, r/politics, r/pics, r/aww, and r/memes.\n",
    "\n",
    "## An Example of Community-specific Analysis\n",
    "\n",
    "We can understand a community by limiting votes to users who frequent a particular subreddit. This allows us to compute the *relative interest* in a subreddit.\n",
    "\n",
    "*Interest* in a subreddit can be defined as the percentage of votes made within the subreddit. *Relative interest* is the same percentage, but only counting votes made by users within a particular community.\n",
    "\n",
    "As a test example, I chose r/fountainpens as a base subreddit. Relative interest with respect to r/fountainpens was computed for every subreddit and compared to the absolute interest. The resulting data revealed some interesting facts:\n",
    "\n",
    "- Among top subreddits, r/fountainpens users are more interested in r/pics than the general population of users. However, they are comparitively uninterested in r/politics.\n",
    "- Apart from r/fountainpens itself, the subreddit with the highest degree of relative interest compared to the general population is r/stevenuniverse.\n",
    "- Other high-ranking hobby subreddits for r/fountainpens users are r/houseplants, r/MechanicalKeyboards, and r/Aquariums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the data files to generate a CSV whose rows are the unique subreddits in the \n",
    "# dataset, with columns for the number of votes and submissions in each subreddit.\n",
    "\n",
    "import csv\n",
    "\n",
    "# The subreddits dict will contain the unique subreddits as keys. Values are to be \n",
    "# lists, with the number of submissions as the first entry and the number of votes as \n",
    "# the second entry.\n",
    "subreddits = {}\n",
    "\n",
    "# Read submission_info.txt to populate the subreddits dict and count the submissions\n",
    "# by subreddit.\n",
    "with open('./data/submission_info.txt', encoding=\"utf8\", newline='') as submissions:\n",
    "    reader = csv.DictReader(submissions, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        if row['SUBREDDIT'] not in subreddits: subreddits[row['SUBREDDIT']] = [1,0]\n",
    "        else: subreddits[row['SUBREDDIT']][0] += 1\n",
    "        \n",
    "# Count the number of votes per subreddit.\n",
    "with open('./data/44_million_votes.txt', encoding=\"utf8\", newline='') as votes:\n",
    "    reader = csv.DictReader(votes, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        subreddit_name = row['SUBREDDIT'][2:]\n",
    "        if subreddit_name not in subreddits: subreddits[subreddit_name] = [0,1]\n",
    "        else: subreddits[subreddit_name][1] += 1\n",
    "\n",
    "# Use the subreddits dict to create a list of tuples.\n",
    "subreddits_list = []\n",
    "for subreddit in subreddits:\n",
    "    subreddits_list.append((subreddit, subreddits[subreddit][0], \n",
    "                           subreddits[subreddit][1]))\n",
    "\n",
    "# The list is sorted first by the number of votes (descending), then by the number of \n",
    "# submissions (descending), and finally alphabetically by subreddit name (ascending).\n",
    "subreddits_list.sort(key=lambda subreddit: (-subreddit[2],-subreddit[1],subreddit[0]))\n",
    "\n",
    "# Write the CSV file with the desired information.\n",
    "with open('./data/subreddits.csv', 'w') as file:\n",
    "    file.write('SUBREDDITS,SUBMISSIONS,VOTES')\n",
    "    for subreddit in subreddits_list:\n",
    "        line = (subreddit[0], str(subreddit[1]), str(subreddit[2]))\n",
    "        file.write('\\n' + ','.join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the labels and data required for a bar graph of the top five subreddits.\n",
    "\n",
    "import csv\n",
    "# import matplotlib\n",
    "\n",
    "subreddit_labels = []\n",
    "submissions = []\n",
    "votes = []\n",
    "\n",
    "with open('./data/subreddits.csv', newline = '') as subreddits:\n",
    "    r = 0\n",
    "    reader = csv.DictReader(subreddits)\n",
    "    for row in reader:\n",
    "        subreddit_labels.append(row['SUBREDDITS'])\n",
    "        submissions.append(int(row['SUBMISSIONS']))\n",
    "        votes.append(int(row['VOTES']))\n",
    "        r += 1\n",
    "        if r == 5: break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a bar graph of the top five subreddits.\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy\n",
    "\n",
    "x = numpy.arange(len(subreddit_labels))\n",
    "\n",
    "bar_graph, axes = pyplot.subplots()\n",
    "vote_rectangles = axes.bar(x - bar_width/2, votes, bar_width, label='Votes')\n",
    "submission_rectangles = axes.bar(x + bar_width/2, submissions, bar_width, label='Submissions')\n",
    "\n",
    "axes.set_ylabel('Totals')\n",
    "axes.set_title('Top five subreddits by votes and submissions')\n",
    "axes.set_xticks(x)\n",
    "axes.set_xticklabels(subreddit_labels)\n",
    "axes.legend()\n",
    "\n",
    "bar_graph.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a dataframe whose rows are the subreddits in the data set, with a \n",
    "# column for the subreddit name, upvotes, downvotes, and total votes. The test \n",
    "# argument can be used to filter rows of the data set by the indicated criteron.\n",
    "def vote_totals(test=lambda x: True, chunk_size=100000):\n",
    "    reader = pd.read_csv('./data/44_million_votes.txt', sep='\\t', chunksize=chunk_size)\n",
    "    \n",
    "    column_names = ['SUBREDDIT', 'UPVOTES', 'DOWNVOTES', 'VOTES']\n",
    "    subreddit_frame = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    r=0\n",
    "    first_iteration = True\n",
    "    for chunk in reader:\n",
    "        boolean_series_up = chunk.apply(lambda x: test(x) and x['VOTE']=='upvote', axis=1)\n",
    "        boolean_series_down = chunk.apply(lambda x: test(x) and x['VOTE']=='downvote', axis=1)\n",
    "        filtered_chunk_up = chunk[boolean_series_up]\n",
    "        filtered_chunk_down = chunk[boolean_series_down]\n",
    "        if first_iteration:\n",
    "            upvote_counter = filtered_chunk_up['SUBREDDIT'].value_counts()\n",
    "            downvote_counter = filtered_chunk_down['SUBREDDIT'].value_counts()\n",
    "            first_iteration = False\n",
    "            r+=1\n",
    "            print(r, 'chunks processed.')\n",
    "        else:\n",
    "            upvote_counter = upvote_counter.add(filtered_chunk_up['SUBREDDIT'].value_counts(), fill_value=0)\n",
    "            downvote_counter = downvote_counter.add(filtered_chunk_down['SUBREDDIT'].value_counts(), fill_value=0)\n",
    "            r+=1\n",
    "            print(r, 'chunks processed.')\n",
    "    \n",
    "    counter = upvote_counter.add(downvote_counter, fill_value = 0)\n",
    "    df = pd.concat([upvote_counter.rename('UPVOTES'), downvote_counter.rename('DOWNVOTES'), counter.rename('TOTAL_VOTES')], axis=1)\n",
    "    df = df.fillna(0)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a set consisting of the entries in a particular column of a CSV. The\n",
    "# rows can be filtered by a test condition.\n",
    "def get_column_as_set(filename, column_name, test=lambda x: True, chunk_size=10000000):\n",
    "    reader = pd.read_csv(filename, sep='\\t', chunksize=chunk_size)\n",
    "    output_set = set()\n",
    "    \n",
    "    for chunk in reader:\n",
    "        boolean_series = chunk.apply(test, axis=1)\n",
    "        filtered_chunk = chunk[boolean_series]\n",
    "        output_set = set(filtered_chunk[column_name]).union(output_set)\n",
    "        \n",
    "    return output_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain set of users who only browse r/fountainpens.\n",
    "fp_redditors = get_column_as_set('./data/44_million_votes.txt', 'USERNAME', test=lambda x: True if x['SUBREDDIT'] == 'r/fountainpens' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 chunks processed.\n",
      "2 chunks processed.\n",
      "3 chunks processed.\n",
      "4 chunks processed.\n",
      "5 chunks processed.\n",
      "6 chunks processed.\n",
      "7 chunks processed.\n",
      "8 chunks processed.\n",
      "9 chunks processed.\n",
      "10 chunks processed.\n",
      "11 chunks processed.\n",
      "12 chunks processed.\n",
      "13 chunks processed.\n",
      "14 chunks processed.\n",
      "15 chunks processed.\n",
      "16 chunks processed.\n",
      "17 chunks processed.\n",
      "18 chunks processed.\n",
      "19 chunks processed.\n",
      "20 chunks processed.\n",
      "21 chunks processed.\n",
      "22 chunks processed.\n",
      "23 chunks processed.\n",
      "24 chunks processed.\n",
      "25 chunks processed.\n",
      "26 chunks processed.\n",
      "27 chunks processed.\n",
      "28 chunks processed.\n",
      "29 chunks processed.\n",
      "30 chunks processed.\n",
      "31 chunks processed.\n",
      "32 chunks processed.\n",
      "33 chunks processed.\n",
      "34 chunks processed.\n",
      "35 chunks processed.\n",
      "36 chunks processed.\n",
      "37 chunks processed.\n",
      "38 chunks processed.\n",
      "39 chunks processed.\n",
      "40 chunks processed.\n",
      "41 chunks processed.\n",
      "42 chunks processed.\n",
      "43 chunks processed.\n",
      "44 chunks processed.\n",
      "45 chunks processed.\n",
      "46 chunks processed.\n",
      "47 chunks processed.\n",
      "48 chunks processed.\n",
      "49 chunks processed.\n",
      "50 chunks processed.\n",
      "51 chunks processed.\n",
      "52 chunks processed.\n",
      "53 chunks processed.\n",
      "54 chunks processed.\n",
      "55 chunks processed.\n",
      "56 chunks processed.\n",
      "57 chunks processed.\n",
      "58 chunks processed.\n",
      "59 chunks processed.\n",
      "60 chunks processed.\n",
      "61 chunks processed.\n",
      "62 chunks processed.\n",
      "63 chunks processed.\n",
      "64 chunks processed.\n",
      "65 chunks processed.\n",
      "66 chunks processed.\n",
      "67 chunks processed.\n",
      "68 chunks processed.\n",
      "69 chunks processed.\n",
      "70 chunks processed.\n",
      "71 chunks processed.\n",
      "72 chunks processed.\n",
      "73 chunks processed.\n",
      "74 chunks processed.\n",
      "75 chunks processed.\n",
      "76 chunks processed.\n",
      "77 chunks processed.\n",
      "78 chunks processed.\n",
      "79 chunks processed.\n",
      "80 chunks processed.\n",
      "81 chunks processed.\n",
      "82 chunks processed.\n",
      "83 chunks processed.\n",
      "84 chunks processed.\n",
      "85 chunks processed.\n",
      "86 chunks processed.\n",
      "87 chunks processed.\n",
      "88 chunks processed.\n",
      "89 chunks processed.\n",
      "90 chunks processed.\n",
      "91 chunks processed.\n",
      "92 chunks processed.\n",
      "93 chunks processed.\n",
      "94 chunks processed.\n",
      "95 chunks processed.\n",
      "96 chunks processed.\n",
      "97 chunks processed.\n",
      "98 chunks processed.\n",
      "99 chunks processed.\n",
      "100 chunks processed.\n",
      "101 chunks processed.\n",
      "102 chunks processed.\n",
      "103 chunks processed.\n",
      "104 chunks processed.\n",
      "105 chunks processed.\n",
      "106 chunks processed.\n",
      "107 chunks processed.\n",
      "108 chunks processed.\n",
      "109 chunks processed.\n",
      "110 chunks processed.\n",
      "111 chunks processed.\n",
      "112 chunks processed.\n",
      "113 chunks processed.\n",
      "114 chunks processed.\n",
      "115 chunks processed.\n",
      "116 chunks processed.\n",
      "117 chunks processed.\n",
      "118 chunks processed.\n",
      "119 chunks processed.\n",
      "120 chunks processed.\n",
      "121 chunks processed.\n",
      "122 chunks processed.\n",
      "123 chunks processed.\n",
      "124 chunks processed.\n",
      "125 chunks processed.\n",
      "126 chunks processed.\n",
      "127 chunks processed.\n",
      "128 chunks processed.\n",
      "129 chunks processed.\n",
      "130 chunks processed.\n",
      "131 chunks processed.\n",
      "132 chunks processed.\n",
      "133 chunks processed.\n",
      "134 chunks processed.\n",
      "135 chunks processed.\n",
      "136 chunks processed.\n",
      "137 chunks processed.\n",
      "138 chunks processed.\n",
      "139 chunks processed.\n",
      "140 chunks processed.\n",
      "141 chunks processed.\n",
      "142 chunks processed.\n",
      "143 chunks processed.\n",
      "144 chunks processed.\n",
      "145 chunks processed.\n",
      "146 chunks processed.\n",
      "147 chunks processed.\n",
      "148 chunks processed.\n",
      "149 chunks processed.\n",
      "150 chunks processed.\n",
      "151 chunks processed.\n",
      "152 chunks processed.\n",
      "153 chunks processed.\n",
      "154 chunks processed.\n",
      "155 chunks processed.\n",
      "156 chunks processed.\n",
      "157 chunks processed.\n",
      "158 chunks processed.\n",
      "159 chunks processed.\n",
      "160 chunks processed.\n",
      "161 chunks processed.\n",
      "162 chunks processed.\n",
      "163 chunks processed.\n",
      "164 chunks processed.\n",
      "165 chunks processed.\n",
      "166 chunks processed.\n",
      "167 chunks processed.\n",
      "168 chunks processed.\n",
      "169 chunks processed.\n",
      "170 chunks processed.\n",
      "171 chunks processed.\n",
      "172 chunks processed.\n",
      "173 chunks processed.\n",
      "174 chunks processed.\n",
      "175 chunks processed.\n",
      "176 chunks processed.\n",
      "177 chunks processed.\n",
      "178 chunks processed.\n",
      "179 chunks processed.\n",
      "180 chunks processed.\n",
      "181 chunks processed.\n",
      "182 chunks processed.\n",
      "183 chunks processed.\n",
      "184 chunks processed.\n",
      "185 chunks processed.\n",
      "186 chunks processed.\n",
      "187 chunks processed.\n",
      "188 chunks processed.\n",
      "189 chunks processed.\n",
      "190 chunks processed.\n",
      "191 chunks processed.\n",
      "192 chunks processed.\n",
      "193 chunks processed.\n",
      "194 chunks processed.\n",
      "195 chunks processed.\n",
      "196 chunks processed.\n",
      "197 chunks processed.\n",
      "198 chunks processed.\n",
      "199 chunks processed.\n",
      "200 chunks processed.\n",
      "201 chunks processed.\n",
      "202 chunks processed.\n",
      "203 chunks processed.\n",
      "204 chunks processed.\n",
      "205 chunks processed.\n",
      "206 chunks processed.\n",
      "207 chunks processed.\n",
      "208 chunks processed.\n",
      "209 chunks processed.\n",
      "210 chunks processed.\n",
      "211 chunks processed.\n",
      "212 chunks processed.\n",
      "213 chunks processed.\n",
      "214 chunks processed.\n",
      "215 chunks processed.\n",
      "216 chunks processed.\n",
      "217 chunks processed.\n",
      "218 chunks processed.\n",
      "219 chunks processed.\n",
      "220 chunks processed.\n",
      "221 chunks processed.\n",
      "222 chunks processed.\n",
      "223 chunks processed.\n",
      "224 chunks processed.\n",
      "225 chunks processed.\n",
      "226 chunks processed.\n",
      "227 chunks processed.\n",
      "228 chunks processed.\n",
      "229 chunks processed.\n",
      "230 chunks processed.\n",
      "231 chunks processed.\n",
      "232 chunks processed.\n",
      "233 chunks processed.\n",
      "234 chunks processed.\n",
      "235 chunks processed.\n",
      "236 chunks processed.\n",
      "237 chunks processed.\n",
      "238 chunks processed.\n",
      "239 chunks processed.\n",
      "240 chunks processed.\n",
      "241 chunks processed.\n",
      "242 chunks processed.\n",
      "243 chunks processed.\n",
      "244 chunks processed.\n",
      "245 chunks processed.\n",
      "246 chunks processed.\n",
      "247 chunks processed.\n",
      "248 chunks processed.\n",
      "249 chunks processed.\n",
      "250 chunks processed.\n",
      "251 chunks processed.\n",
      "252 chunks processed.\n",
      "253 chunks processed.\n",
      "254 chunks processed.\n",
      "255 chunks processed.\n",
      "256 chunks processed.\n",
      "257 chunks processed.\n",
      "258 chunks processed.\n",
      "259 chunks processed.\n",
      "260 chunks processed.\n",
      "261 chunks processed.\n",
      "262 chunks processed.\n",
      "263 chunks processed.\n",
      "264 chunks processed.\n",
      "265 chunks processed.\n",
      "266 chunks processed.\n",
      "267 chunks processed.\n",
      "268 chunks processed.\n",
      "269 chunks processed.\n",
      "270 chunks processed.\n",
      "271 chunks processed.\n",
      "272 chunks processed.\n",
      "273 chunks processed.\n",
      "274 chunks processed.\n",
      "275 chunks processed.\n",
      "276 chunks processed.\n",
      "277 chunks processed.\n",
      "278 chunks processed.\n",
      "279 chunks processed.\n",
      "280 chunks processed.\n",
      "281 chunks processed.\n",
      "282 chunks processed.\n",
      "283 chunks processed.\n",
      "284 chunks processed.\n",
      "285 chunks processed.\n",
      "286 chunks processed.\n",
      "287 chunks processed.\n",
      "288 chunks processed.\n",
      "289 chunks processed.\n",
      "290 chunks processed.\n",
      "291 chunks processed.\n",
      "292 chunks processed.\n",
      "293 chunks processed.\n",
      "294 chunks processed.\n",
      "295 chunks processed.\n",
      "296 chunks processed.\n",
      "297 chunks processed.\n",
      "298 chunks processed.\n",
      "299 chunks processed.\n",
      "300 chunks processed.\n",
      "301 chunks processed.\n",
      "302 chunks processed.\n",
      "303 chunks processed.\n",
      "304 chunks processed.\n",
      "305 chunks processed.\n",
      "306 chunks processed.\n",
      "307 chunks processed.\n",
      "308 chunks processed.\n",
      "309 chunks processed.\n",
      "310 chunks processed.\n",
      "311 chunks processed.\n",
      "312 chunks processed.\n",
      "313 chunks processed.\n",
      "314 chunks processed.\n",
      "315 chunks processed.\n",
      "316 chunks processed.\n",
      "317 chunks processed.\n",
      "318 chunks processed.\n",
      "319 chunks processed.\n",
      "320 chunks processed.\n",
      "321 chunks processed.\n",
      "322 chunks processed.\n",
      "323 chunks processed.\n",
      "324 chunks processed.\n",
      "325 chunks processed.\n",
      "326 chunks processed.\n",
      "327 chunks processed.\n",
      "328 chunks processed.\n",
      "329 chunks processed.\n",
      "330 chunks processed.\n",
      "331 chunks processed.\n",
      "332 chunks processed.\n",
      "333 chunks processed.\n",
      "334 chunks processed.\n",
      "335 chunks processed.\n",
      "336 chunks processed.\n",
      "337 chunks processed.\n",
      "338 chunks processed.\n",
      "339 chunks processed.\n",
      "340 chunks processed.\n",
      "341 chunks processed.\n",
      "342 chunks processed.\n",
      "343 chunks processed.\n",
      "344 chunks processed.\n",
      "345 chunks processed.\n",
      "346 chunks processed.\n",
      "347 chunks processed.\n",
      "348 chunks processed.\n",
      "349 chunks processed.\n",
      "350 chunks processed.\n",
      "351 chunks processed.\n",
      "352 chunks processed.\n",
      "353 chunks processed.\n",
      "354 chunks processed.\n",
      "355 chunks processed.\n",
      "356 chunks processed.\n",
      "357 chunks processed.\n",
      "358 chunks processed.\n",
      "359 chunks processed.\n",
      "360 chunks processed.\n",
      "361 chunks processed.\n",
      "362 chunks processed.\n",
      "363 chunks processed.\n",
      "364 chunks processed.\n",
      "365 chunks processed.\n",
      "366 chunks processed.\n",
      "367 chunks processed.\n",
      "368 chunks processed.\n",
      "369 chunks processed.\n",
      "370 chunks processed.\n",
      "371 chunks processed.\n",
      "372 chunks processed.\n",
      "373 chunks processed.\n",
      "374 chunks processed.\n",
      "375 chunks processed.\n",
      "376 chunks processed.\n",
      "377 chunks processed.\n",
      "378 chunks processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379 chunks processed.\n",
      "380 chunks processed.\n",
      "381 chunks processed.\n",
      "382 chunks processed.\n",
      "383 chunks processed.\n",
      "384 chunks processed.\n",
      "385 chunks processed.\n",
      "386 chunks processed.\n",
      "387 chunks processed.\n",
      "388 chunks processed.\n",
      "389 chunks processed.\n",
      "390 chunks processed.\n",
      "391 chunks processed.\n",
      "392 chunks processed.\n",
      "393 chunks processed.\n",
      "394 chunks processed.\n",
      "395 chunks processed.\n",
      "396 chunks processed.\n",
      "397 chunks processed.\n",
      "398 chunks processed.\n",
      "399 chunks processed.\n",
      "400 chunks processed.\n",
      "401 chunks processed.\n",
      "402 chunks processed.\n",
      "403 chunks processed.\n",
      "404 chunks processed.\n",
      "405 chunks processed.\n",
      "406 chunks processed.\n",
      "407 chunks processed.\n",
      "408 chunks processed.\n",
      "409 chunks processed.\n",
      "410 chunks processed.\n",
      "411 chunks processed.\n",
      "412 chunks processed.\n",
      "413 chunks processed.\n",
      "414 chunks processed.\n",
      "415 chunks processed.\n",
      "416 chunks processed.\n",
      "417 chunks processed.\n",
      "418 chunks processed.\n",
      "419 chunks processed.\n",
      "420 chunks processed.\n",
      "421 chunks processed.\n",
      "422 chunks processed.\n",
      "423 chunks processed.\n",
      "424 chunks processed.\n",
      "425 chunks processed.\n",
      "426 chunks processed.\n",
      "427 chunks processed.\n",
      "428 chunks processed.\n",
      "429 chunks processed.\n",
      "430 chunks processed.\n",
      "431 chunks processed.\n",
      "432 chunks processed.\n",
      "433 chunks processed.\n",
      "434 chunks processed.\n",
      "435 chunks processed.\n",
      "436 chunks processed.\n",
      "437 chunks processed.\n",
      "438 chunks processed.\n",
      "439 chunks processed.\n",
      "440 chunks processed.\n",
      "441 chunks processed.\n",
      "442 chunks processed.\n",
      "443 chunks processed.\n",
      "444 chunks processed.\n",
      "445 chunks processed.\n",
      "446 chunks processed.\n",
      "447 chunks processed.\n",
      "448 chunks processed.\n",
      "449 chunks processed.\n"
     ]
    }
   ],
   "source": [
    "# Tabulate voting data from r/fountainpen users.\n",
    "fp_votes = vote_totals(lambda x: x['USERNAME'] in fp_redditors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 chunks processed.\n",
      "2 chunks processed.\n",
      "3 chunks processed.\n",
      "4 chunks processed.\n",
      "5 chunks processed.\n",
      "6 chunks processed.\n",
      "7 chunks processed.\n",
      "8 chunks processed.\n",
      "9 chunks processed.\n",
      "10 chunks processed.\n",
      "11 chunks processed.\n",
      "12 chunks processed.\n",
      "13 chunks processed.\n",
      "14 chunks processed.\n",
      "15 chunks processed.\n",
      "16 chunks processed.\n",
      "17 chunks processed.\n",
      "18 chunks processed.\n",
      "19 chunks processed.\n",
      "20 chunks processed.\n",
      "21 chunks processed.\n",
      "22 chunks processed.\n",
      "23 chunks processed.\n",
      "24 chunks processed.\n",
      "25 chunks processed.\n",
      "26 chunks processed.\n",
      "27 chunks processed.\n",
      "28 chunks processed.\n",
      "29 chunks processed.\n",
      "30 chunks processed.\n",
      "31 chunks processed.\n",
      "32 chunks processed.\n",
      "33 chunks processed.\n",
      "34 chunks processed.\n",
      "35 chunks processed.\n",
      "36 chunks processed.\n",
      "37 chunks processed.\n",
      "38 chunks processed.\n",
      "39 chunks processed.\n",
      "40 chunks processed.\n",
      "41 chunks processed.\n",
      "42 chunks processed.\n",
      "43 chunks processed.\n",
      "44 chunks processed.\n",
      "45 chunks processed.\n",
      "46 chunks processed.\n",
      "47 chunks processed.\n",
      "48 chunks processed.\n",
      "49 chunks processed.\n",
      "50 chunks processed.\n",
      "51 chunks processed.\n",
      "52 chunks processed.\n",
      "53 chunks processed.\n",
      "54 chunks processed.\n",
      "55 chunks processed.\n",
      "56 chunks processed.\n",
      "57 chunks processed.\n",
      "58 chunks processed.\n",
      "59 chunks processed.\n",
      "60 chunks processed.\n",
      "61 chunks processed.\n",
      "62 chunks processed.\n",
      "63 chunks processed.\n",
      "64 chunks processed.\n",
      "65 chunks processed.\n",
      "66 chunks processed.\n",
      "67 chunks processed.\n",
      "68 chunks processed.\n",
      "69 chunks processed.\n",
      "70 chunks processed.\n",
      "71 chunks processed.\n",
      "72 chunks processed.\n",
      "73 chunks processed.\n",
      "74 chunks processed.\n",
      "75 chunks processed.\n",
      "76 chunks processed.\n",
      "77 chunks processed.\n",
      "78 chunks processed.\n",
      "79 chunks processed.\n",
      "80 chunks processed.\n",
      "81 chunks processed.\n",
      "82 chunks processed.\n",
      "83 chunks processed.\n",
      "84 chunks processed.\n",
      "85 chunks processed.\n",
      "86 chunks processed.\n",
      "87 chunks processed.\n",
      "88 chunks processed.\n",
      "89 chunks processed.\n",
      "90 chunks processed.\n",
      "91 chunks processed.\n",
      "92 chunks processed.\n",
      "93 chunks processed.\n",
      "94 chunks processed.\n",
      "95 chunks processed.\n",
      "96 chunks processed.\n",
      "97 chunks processed.\n",
      "98 chunks processed.\n",
      "99 chunks processed.\n",
      "100 chunks processed.\n",
      "101 chunks processed.\n",
      "102 chunks processed.\n",
      "103 chunks processed.\n",
      "104 chunks processed.\n",
      "105 chunks processed.\n",
      "106 chunks processed.\n",
      "107 chunks processed.\n",
      "108 chunks processed.\n",
      "109 chunks processed.\n",
      "110 chunks processed.\n",
      "111 chunks processed.\n",
      "112 chunks processed.\n",
      "113 chunks processed.\n",
      "114 chunks processed.\n",
      "115 chunks processed.\n",
      "116 chunks processed.\n",
      "117 chunks processed.\n",
      "118 chunks processed.\n",
      "119 chunks processed.\n",
      "120 chunks processed.\n",
      "121 chunks processed.\n",
      "122 chunks processed.\n",
      "123 chunks processed.\n",
      "124 chunks processed.\n",
      "125 chunks processed.\n",
      "126 chunks processed.\n",
      "127 chunks processed.\n",
      "128 chunks processed.\n",
      "129 chunks processed.\n",
      "130 chunks processed.\n",
      "131 chunks processed.\n",
      "132 chunks processed.\n",
      "133 chunks processed.\n",
      "134 chunks processed.\n",
      "135 chunks processed.\n",
      "136 chunks processed.\n",
      "137 chunks processed.\n",
      "138 chunks processed.\n",
      "139 chunks processed.\n",
      "140 chunks processed.\n",
      "141 chunks processed.\n",
      "142 chunks processed.\n",
      "143 chunks processed.\n",
      "144 chunks processed.\n",
      "145 chunks processed.\n",
      "146 chunks processed.\n",
      "147 chunks processed.\n",
      "148 chunks processed.\n",
      "149 chunks processed.\n",
      "150 chunks processed.\n",
      "151 chunks processed.\n",
      "152 chunks processed.\n",
      "153 chunks processed.\n",
      "154 chunks processed.\n",
      "155 chunks processed.\n",
      "156 chunks processed.\n",
      "157 chunks processed.\n",
      "158 chunks processed.\n",
      "159 chunks processed.\n",
      "160 chunks processed.\n",
      "161 chunks processed.\n",
      "162 chunks processed.\n",
      "163 chunks processed.\n",
      "164 chunks processed.\n",
      "165 chunks processed.\n",
      "166 chunks processed.\n",
      "167 chunks processed.\n",
      "168 chunks processed.\n",
      "169 chunks processed.\n",
      "170 chunks processed.\n",
      "171 chunks processed.\n",
      "172 chunks processed.\n",
      "173 chunks processed.\n",
      "174 chunks processed.\n",
      "175 chunks processed.\n",
      "176 chunks processed.\n",
      "177 chunks processed.\n",
      "178 chunks processed.\n",
      "179 chunks processed.\n",
      "180 chunks processed.\n",
      "181 chunks processed.\n",
      "182 chunks processed.\n",
      "183 chunks processed.\n",
      "184 chunks processed.\n",
      "185 chunks processed.\n",
      "186 chunks processed.\n",
      "187 chunks processed.\n",
      "188 chunks processed.\n",
      "189 chunks processed.\n",
      "190 chunks processed.\n",
      "191 chunks processed.\n",
      "192 chunks processed.\n",
      "193 chunks processed.\n",
      "194 chunks processed.\n",
      "195 chunks processed.\n",
      "196 chunks processed.\n",
      "197 chunks processed.\n",
      "198 chunks processed.\n",
      "199 chunks processed.\n",
      "200 chunks processed.\n",
      "201 chunks processed.\n",
      "202 chunks processed.\n",
      "203 chunks processed.\n",
      "204 chunks processed.\n",
      "205 chunks processed.\n",
      "206 chunks processed.\n",
      "207 chunks processed.\n",
      "208 chunks processed.\n",
      "209 chunks processed.\n",
      "210 chunks processed.\n",
      "211 chunks processed.\n",
      "212 chunks processed.\n",
      "213 chunks processed.\n",
      "214 chunks processed.\n",
      "215 chunks processed.\n",
      "216 chunks processed.\n",
      "217 chunks processed.\n",
      "218 chunks processed.\n",
      "219 chunks processed.\n",
      "220 chunks processed.\n",
      "221 chunks processed.\n",
      "222 chunks processed.\n",
      "223 chunks processed.\n",
      "224 chunks processed.\n",
      "225 chunks processed.\n",
      "226 chunks processed.\n",
      "227 chunks processed.\n",
      "228 chunks processed.\n",
      "229 chunks processed.\n",
      "230 chunks processed.\n",
      "231 chunks processed.\n",
      "232 chunks processed.\n",
      "233 chunks processed.\n",
      "234 chunks processed.\n",
      "235 chunks processed.\n",
      "236 chunks processed.\n",
      "237 chunks processed.\n",
      "238 chunks processed.\n",
      "239 chunks processed.\n",
      "240 chunks processed.\n",
      "241 chunks processed.\n",
      "242 chunks processed.\n",
      "243 chunks processed.\n",
      "244 chunks processed.\n",
      "245 chunks processed.\n",
      "246 chunks processed.\n",
      "247 chunks processed.\n",
      "248 chunks processed.\n",
      "249 chunks processed.\n",
      "250 chunks processed.\n",
      "251 chunks processed.\n",
      "252 chunks processed.\n",
      "253 chunks processed.\n",
      "254 chunks processed.\n",
      "255 chunks processed.\n",
      "256 chunks processed.\n",
      "257 chunks processed.\n",
      "258 chunks processed.\n",
      "259 chunks processed.\n",
      "260 chunks processed.\n",
      "261 chunks processed.\n",
      "262 chunks processed.\n",
      "263 chunks processed.\n",
      "264 chunks processed.\n",
      "265 chunks processed.\n",
      "266 chunks processed.\n",
      "267 chunks processed.\n",
      "268 chunks processed.\n",
      "269 chunks processed.\n",
      "270 chunks processed.\n",
      "271 chunks processed.\n",
      "272 chunks processed.\n",
      "273 chunks processed.\n",
      "274 chunks processed.\n",
      "275 chunks processed.\n",
      "276 chunks processed.\n",
      "277 chunks processed.\n",
      "278 chunks processed.\n",
      "279 chunks processed.\n",
      "280 chunks processed.\n",
      "281 chunks processed.\n",
      "282 chunks processed.\n",
      "283 chunks processed.\n",
      "284 chunks processed.\n",
      "285 chunks processed.\n",
      "286 chunks processed.\n",
      "287 chunks processed.\n",
      "288 chunks processed.\n",
      "289 chunks processed.\n",
      "290 chunks processed.\n",
      "291 chunks processed.\n",
      "292 chunks processed.\n",
      "293 chunks processed.\n",
      "294 chunks processed.\n",
      "295 chunks processed.\n",
      "296 chunks processed.\n",
      "297 chunks processed.\n",
      "298 chunks processed.\n",
      "299 chunks processed.\n",
      "300 chunks processed.\n",
      "301 chunks processed.\n",
      "302 chunks processed.\n",
      "303 chunks processed.\n",
      "304 chunks processed.\n",
      "305 chunks processed.\n",
      "306 chunks processed.\n",
      "307 chunks processed.\n",
      "308 chunks processed.\n",
      "309 chunks processed.\n",
      "310 chunks processed.\n",
      "311 chunks processed.\n",
      "312 chunks processed.\n",
      "313 chunks processed.\n",
      "314 chunks processed.\n",
      "315 chunks processed.\n",
      "316 chunks processed.\n",
      "317 chunks processed.\n",
      "318 chunks processed.\n",
      "319 chunks processed.\n",
      "320 chunks processed.\n",
      "321 chunks processed.\n",
      "322 chunks processed.\n",
      "323 chunks processed.\n",
      "324 chunks processed.\n",
      "325 chunks processed.\n",
      "326 chunks processed.\n",
      "327 chunks processed.\n",
      "328 chunks processed.\n",
      "329 chunks processed.\n",
      "330 chunks processed.\n",
      "331 chunks processed.\n",
      "332 chunks processed.\n",
      "333 chunks processed.\n",
      "334 chunks processed.\n",
      "335 chunks processed.\n",
      "336 chunks processed.\n",
      "337 chunks processed.\n",
      "338 chunks processed.\n",
      "339 chunks processed.\n",
      "340 chunks processed.\n",
      "341 chunks processed.\n",
      "342 chunks processed.\n",
      "343 chunks processed.\n",
      "344 chunks processed.\n",
      "345 chunks processed.\n",
      "346 chunks processed.\n",
      "347 chunks processed.\n",
      "348 chunks processed.\n",
      "349 chunks processed.\n",
      "350 chunks processed.\n",
      "351 chunks processed.\n",
      "352 chunks processed.\n",
      "353 chunks processed.\n",
      "354 chunks processed.\n",
      "355 chunks processed.\n",
      "356 chunks processed.\n",
      "357 chunks processed.\n",
      "358 chunks processed.\n",
      "359 chunks processed.\n",
      "360 chunks processed.\n",
      "361 chunks processed.\n",
      "362 chunks processed.\n",
      "363 chunks processed.\n",
      "364 chunks processed.\n",
      "365 chunks processed.\n",
      "366 chunks processed.\n",
      "367 chunks processed.\n",
      "368 chunks processed.\n",
      "369 chunks processed.\n",
      "370 chunks processed.\n",
      "371 chunks processed.\n",
      "372 chunks processed.\n",
      "373 chunks processed.\n",
      "374 chunks processed.\n",
      "375 chunks processed.\n",
      "376 chunks processed.\n",
      "377 chunks processed.\n",
      "378 chunks processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379 chunks processed.\n",
      "380 chunks processed.\n",
      "381 chunks processed.\n",
      "382 chunks processed.\n",
      "383 chunks processed.\n",
      "384 chunks processed.\n",
      "385 chunks processed.\n",
      "386 chunks processed.\n",
      "387 chunks processed.\n",
      "388 chunks processed.\n",
      "389 chunks processed.\n",
      "390 chunks processed.\n",
      "391 chunks processed.\n",
      "392 chunks processed.\n",
      "393 chunks processed.\n",
      "394 chunks processed.\n",
      "395 chunks processed.\n",
      "396 chunks processed.\n",
      "397 chunks processed.\n",
      "398 chunks processed.\n",
      "399 chunks processed.\n",
      "400 chunks processed.\n",
      "401 chunks processed.\n",
      "402 chunks processed.\n",
      "403 chunks processed.\n",
      "404 chunks processed.\n",
      "405 chunks processed.\n",
      "406 chunks processed.\n",
      "407 chunks processed.\n",
      "408 chunks processed.\n",
      "409 chunks processed.\n",
      "410 chunks processed.\n",
      "411 chunks processed.\n",
      "412 chunks processed.\n",
      "413 chunks processed.\n",
      "414 chunks processed.\n",
      "415 chunks processed.\n",
      "416 chunks processed.\n",
      "417 chunks processed.\n",
      "418 chunks processed.\n",
      "419 chunks processed.\n",
      "420 chunks processed.\n",
      "421 chunks processed.\n",
      "422 chunks processed.\n",
      "423 chunks processed.\n",
      "424 chunks processed.\n",
      "425 chunks processed.\n",
      "426 chunks processed.\n",
      "427 chunks processed.\n",
      "428 chunks processed.\n",
      "429 chunks processed.\n",
      "430 chunks processed.\n",
      "431 chunks processed.\n",
      "432 chunks processed.\n",
      "433 chunks processed.\n",
      "434 chunks processed.\n",
      "435 chunks processed.\n",
      "436 chunks processed.\n",
      "437 chunks processed.\n",
      "438 chunks processed.\n",
      "439 chunks processed.\n",
      "440 chunks processed.\n",
      "441 chunks processed.\n",
      "442 chunks processed.\n",
      "443 chunks processed.\n",
      "444 chunks processed.\n",
      "445 chunks processed.\n",
      "446 chunks processed.\n",
      "447 chunks processed.\n",
      "448 chunks processed.\n",
      "449 chunks processed.\n"
     ]
    }
   ],
   "source": [
    "# Tabulate all votes.\n",
    "all_votes = vote_totals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the above data; only include subreddits with votes from r/fountainpens.\n",
    "summary_df = pd.concat([fp_votes, all_votes.rename(columns={'UPVOTES':'ALL_UPVOTES', 'DOWNVOTES':'ALL_DOWNVOTES', 'TOTAL_VOTES':'ALL_TOTAL_VOTES'})], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPVOTES</th>\n",
       "      <th>DOWNVOTES</th>\n",
       "      <th>TOTAL_VOTES</th>\n",
       "      <th>ALL_UPVOTES</th>\n",
       "      <th>ALL_DOWNVOTES</th>\n",
       "      <th>ALL_TOTAL_VOTES</th>\n",
       "      <th>RELATIVE_POPULARITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r/0b0t</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r/0to100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r/1000ccplus</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>-0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r/100yearsago</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r/1022</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u/vredditshare</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u/webhostingservicee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u/well_hello2u</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u/wynterRose1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u/xChubbyrabbitx</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18574 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      UPVOTES  DOWNVOTES  TOTAL_VOTES  ALL_UPVOTES  \\\n",
       "r/0b0t                    6.0        2.0          8.0          7.0   \n",
       "r/0to100                  1.0        0.0          1.0          3.0   \n",
       "r/1000ccplus              4.0        0.0          4.0       1016.0   \n",
       "r/100yearsago            14.0        0.0         14.0        651.0   \n",
       "r/1022                   53.0        0.0         53.0        178.0   \n",
       "...                       ...        ...          ...          ...   \n",
       "u/vredditshare            0.0        1.0          1.0          0.0   \n",
       "u/webhostingservicee      0.0        2.0          2.0          0.0   \n",
       "u/well_hello2u            0.0        1.0          1.0          0.0   \n",
       "u/wynterRose1998          0.0        1.0          1.0          0.0   \n",
       "u/xChubbyrabbitx          0.0        1.0          1.0          1.0   \n",
       "\n",
       "                      ALL_DOWNVOTES  ALL_TOTAL_VOTES  RELATIVE_POPULARITY  \n",
       "r/0b0t                          3.0             10.0             0.000011  \n",
       "r/0to100                        0.0              3.0             0.000001  \n",
       "r/1000ccplus                   59.0           1075.0            -0.000018  \n",
       "r/100yearsago                  62.0            713.0             0.000003  \n",
       "r/1022                         40.0            218.0             0.000068  \n",
       "...                             ...              ...                  ...  \n",
       "u/vredditshare                  1.0              1.0             0.000001  \n",
       "u/webhostingservicee            2.0              2.0             0.000003  \n",
       "u/well_hello2u                  1.0              1.0             0.000001  \n",
       "u/wynterRose1998                1.0              1.0             0.000001  \n",
       "u/xChubbyrabbitx                1.0              2.0             0.000001  \n",
       "\n",
       "[18574 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute relative popularities for r/fountainpens and add them to the dataframe.\n",
    "relative_popularity = summary_df.apply(lambda x: x['TOTAL_VOTES']/fp_votes['TOTAL_VOTES'].sum()-x['ALL_TOTAL_VOTES']/all_votes['TOTAL_VOTES'].sum(), axis=1)\n",
    "relative_popularity = relative_popularity.rename('RELATIVE_POPULARITY')\n",
    "summary_df = pd.concat([summary_df, relative_popularity], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data frame.\n",
    "summary_df = summary_df.sort_values(['RELATIVE_POPULARITY', 'ALL_TOTAL_VOTES'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to CSV.\n",
    "summary_df.to_csv(path_or_buf='./data/relative_popularity_r-fountainpens.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
